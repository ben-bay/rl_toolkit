
# 10-Armed Testbed

Run simple exploration algorithms on the toy multi-armed bandit problem "10-armed testbed"!

To run:

    python3 10_armed_testbed.py [--narms] [--mean] [--variance] [--ntimesteps] [--nruns]

![Bandits](https://raw.githubusercontent.com/ben-bay/rl_toolkit/bandits/plot.png)
